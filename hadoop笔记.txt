网络配置：
    /etc/hosts 文件类似于DNS，可以实现标记符到 ip 的映射 
    /etc/hostname 本机的名称 (hostname 命令查看)
    修改网络IP为静态IP：修改/etc/sysconfig/network-scripts/ifcfg-ens33中的BOOTPROTO="static"，末尾加上IPADDR=X.X.X.X,GATEWAY=X.X.X.X,DNS1=X.X.X.X (hostname -i 命令查看)

hadoop不同版本：
    Apache 原始。免费
    Cloudera CDH 收费
    Hortonworks HDP 收费
    CDP 收费

Hadoop 3.1.3 - Jdk 8   

如果运行 hadoop 时提示找不到 JAVA_HOME，是因为没有设置系统级的 JAVA_HOME 变量（/etc/profile）。用户级别的 JAVA_HOME 不起作用（~/.bash_profile）
/etc/profile 会导入 /etc/profile.d/*.sh 文件的环境变量。所以在 /etc/profile.d/ 中创建后缀为.sh文件，写入环境变量，也是系统级的。 source file_name 重新加载文件

概念：
    common 辅助工具
    HDFS 数据存储（ DataNode / NameNode / SecondaryNameNode）
    Yarn 资源调度（NodeManager / ResourceManager）
    MapReduce 计算

    ResourceManager: 管理整个hadoop。只有一个
    NodeManager: 管理单个节点。每个节点一个
    DataNode: 数据节点。每个节点一个
    NameNode: 存储文件的元数据，如文件名，文件目录结构，文件属性，以及每个文件的块列表和块所在的DataNode等。
    SecondaryNameNode: 备用的NameNode
    
    Container 运行任务的容器
    


hadoop 三个节点安排：
    hadoop101: 192.168.153.101, DataNode, NodeManager, NameNode
    hadoop102: 192.168.153.102, DataNode, NodeManager, ResourceManager
    hadoop103: 192.168.153.103, DataNode, NodeManager, SecondaryNameNode
    
    NameNode、SecondaryNameNode、ResourceManager 都比较好内存，尽量安装在不同节点上
    
    historyserver 也在 101 上
    
    http://hadoop101:9870/ NameNode
    http://hadoop102:8088/ ResourceManager
    http://hadoop101:19888/ JobHistory
    

hadoop 配置：
    HADOOP_HOME/etc/hadoop/core-site.xml
    HADOOP_HOME/etc/hadoop/hdfs-site.xml
    HADOOP_HOME/etc/hadoop/yarn-site.xml
    HADOOP_HOME/etc/hadoop/mapred-site.xml
    
命令：
    hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount /wcinput /wcoutput 运行示例代码。输出目录必须不存在
    jps JAVA提供的工具。查看Java进程。显示其PID与程序名。 -m 显示传递的参数。 -l 显示class的完整包名
    start-dfs.sh 启动 hdfs。可在任意节点运行
    start-yarn.sh 启动 yarn。可在任意节点运行
    stop-all.sh 停止hadoop。可在任意节点运行
    mapred --daemon start historyserver 启动历史服务器。必须在历史服务器上运行
    
报错:
    container is running beyond virtual memory limits. https://blog.csdn.net/qq_33202508/article/details/108850153
    如果hadoop崩溃了，可以删掉所有节点的data、logs目录。然后格式化hdfs，一切重来。
    