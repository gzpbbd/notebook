python 2 运行出现SyntaxError: Non-ASCII character '\xe8' in file 是因为源文件中有中文出现： 在第一行加上 
#encoding:utf-8 即可

解析命令行传递的参数
    import argparse
    
	parser = argparse.ArgumentParser(description='Process some integers.')
	parser.add_argument('integers', type=int, nargs='+', help='xxx')
	parser.add_argument('--test_case', type=int, default=1000, help='xxx')

	args = parser.parse_args()
	# args, _ = parser.parse_known_args() 将不能解析的参数放入 _ 中，不报错
	intergets = args.intergets
	test_case = args.test_case
	
	
---- 配置日志的方法：
# 警告：当root logger没有handler时，logging.basicConfig() 会给其添加一个streamHandler，从而可能出现控制台重复输出
import logging
import time
import os


def init_logging(filepath='./log/output.log', log_level=logging.DEBUG):
    # file handler
    abs_path = os.path.abspath(filepath)
    dir_name = os.path.dirname(abs_path)
    if not os.path.exists(dir_name):
        os.makedirs(dir_name)
	
	# 下面格式在pycharm中打印出的日志可以跳转
	# format="%(filename)s:%(lineno)d %(funcName)s %(asctime)s %(levelname)s | "
    #                               "%(message)s" 
    formatter = logging.Formatter(
        "%(levelname)9s %(asctime)s: %(filename)-20s (%(funcName)-20s %(lineno)4d) |  %(message)s",
        datefmt='%H:%M:%S')
    file_handler = logging.FileHandler(filepath, mode='w')
    file_handler.setLevel(log_level)
    file_handler.setFormatter(formatter)

    # stream handle
    console_handler = logging.StreamHandler()
    console_handler.setLevel(log_level)
    console_handler.setFormatter(formatter)

    # setting logging
    logging.getLogger().setLevel(log_level)
    logging.getLogger().addHandler(file_handler)
    logging.getLogger().addHandler(console_handler)
    logging.debug('write log to {}'.format(abs_path))


init_logging(filename='run.log')
logging.debug('debug messages')
logging.warning('warning messages')
logging.error('error messages')


		
多进程编程：
	import multiprocessing as mp

	def fun(queue, kw='kwargs'):
		queue.put('hello')
		queue.put(kw)

	if __name__ == '__main__':
		# 得到 context, context 拥有与 mp 相同的 API
		# 并设置之后子进程被创建的方式。 spwan 方式创建的子进程只保留运行 run 方法必要的数据，不复制无用的文件句柄等
		ctx = mp.get_context('spawn')

		q = ctx.Queue()  # 创建多进程安全的队列
		processes = []
		for i in range(3):
			# 创建 Process，指定子进程要运行的函数及其参数
			processes.append(ctx.Process(target=fun, args=(q,), kwargs={'kw': 'world'}))
		for p in processes:
			# p.daemon = True
			p.start()  # 开始运行子进程
		for p in processes:
			p.join()  # 等待子进程结束
		while not q.empty():
			print(q.get())
		print('end ...')
		
pickle保存数据：
	（1）
	import pickle
	data = {'a': [1, 2, 3], 'b': 'string'}
	with open(PATH, 'wb') as f:
		pickle.dump(data, f) # 保存的是什么类型，加载的就是什么类型
	# ---    
	with open(PATH, 'rb') as f:
		data = pickle.load(f)    	
	（2）
	data_bytes = pickle.dumps(data) # 返回对象的 bytes
	# ---
	data = pickle.loads(data_bytes)
	
保存为json文件：
	（1）
	import json
	PATH = './data.json'
	data = {'a':[1,2,3], 'b':'string'}

	with open(PATH, 'w') as f:
		json.dump(data, f, indent=4)
		
	with open(PATH, 'r') as f:
		data = json.load(f)    
	（2） dumps、loads 作用于 str 类型
	
pandas:
import pandas as pd
wm_train_res = pd.DataFrame(columns=['epoch', 'acc_reward'])
wm_train_res = wm_train_res.append(
                    {'episode': 1, 'acc_reward': 0.98, ignore_index=True)
wm_train_res['epoch'] = wm_train_res['epoch'].astype(int)
df.insert(0, 'algorithm', dir_algorithm['algorithm'])
wm_train_res.to_csv('out.csv', index=False)

pd.read_csv('out.csv')